'''
Si los datos muestran tendencias curas, entonces la regresi√≥n lineal no producir√° resultados muy exactos
cuando se comparan con una regresi√≥n no lineal, porque, como su nombre lo indica, la regresi√≥n lineal sume
que los datos son lineales. Aprendamos sobre regresiones no lineales y apliquemos un ejemplo en python.
En este lab, conectaremos un modelo no lineal con los puntos de tendencia correspondientes al GDP de China
entre los a√±os 1960 y 2014.

Importando librerias necesarias
'''
import numpy as np
import pandas as pd
from src.charts.domain.line_chart import LineChart
from scipy.optimize import curve_fit
from sklearn.metrics import r2_score
#%matplotlib inline
'''
Aunque la regresi√≥n lineal es muy buena para resolver varios problemas, no puede utilizarse en todos los sets de
datos. Primero, recordemos c√≥mo funciona la regresi√≥n lineal, se podr√≠a modelar un set de datos. Modelar una
relaci√≥n lineal entre una variable dependiente y una variable independiente x, tendr√≠a una simple ecuaci√≥n de
grado 1, por ejemplo y = 2*(x) + 3.
'''

class NoLineal:
    def __init__(self):
        self.__path_source_data = 'src/regresion/modules/no_lineal/infrastructure/repositories/'
        self._df = None
        self._popt = None
        self._pcov = None
        pass

    def print_cubic_chart_demo(self):
        lineChart = LineChart()
        lineChart.x = np.arange(-5.0, 5.0, 0.1)
        ##Se puede ajustar la pendiente y la intersecci√≥n para verificar los cambios en el gr√°fico
        lineChart.y = 1*(lineChart.x**3) + 1*(lineChart.x**2) + 1*lineChart.x + 3
        y_noise = 20 * np.random.normal(size = lineChart.x.size)
        lineChart.ydata = lineChart.y + y_noise
        #plt.figure(figsize=(8,6))
        lineChart.plot_default()
        lineChart.set_labels('Variable independiente', 'Variable dependiente')
        return lineChart.print_to_imgb64()

    def print_quad_chart_demo(self):
        lineChart = LineChart()
        lineChart.x = np.arange(-5.0, 5.0, 0.1)
        ##Se puede ajustar la pendiente y la intersecci√≥n para verificar los cambios en el gr√°fico
        lineChart.y = np.power(lineChart.x,2)
        y_noise = 2 * np.random.normal(size = lineChart.x.size)
        lineChart.ydata = lineChart.y + y_noise
        #plt.figure(figsize=(8,6))
        lineChart.plot_default()
        lineChart.set_labels('Variable independiente', 'Variable dependiente')
        return lineChart.print_to_imgb64()

    def print_exponential_chart_demo(self):
        lineChart = LineChart()
        lineChart.x = np.arange(-5.0, 5.0, 0.1)
        ##Se puede ajustar la pendiente y la intersecci√≥n para verificar los cambios en el gr√°fico
        lineChart.y = np.exp(lineChart.x)
        #plt.figure(figsize=(8,6))
        lineChart.plt.plot(lineChart.x, lineChart.y)
        lineChart.set_labels('Variable independiente', 'Variable dependiente')
        return lineChart.print_to_imgb64()

    def print_logarithmic_chart_demo(self):
        lineChart = LineChart()
        lineChart.x = np.arange(-5.0, 5.0, 0.1)
        ##Se puede ajustar la pendiente y la intersecci√≥n para verificar los cambios en el gr√°fico
        lineChart.y = np.log(lineChart.x)
        #plt.figure(figsize=(8,6))
        lineChart.plt.plot(lineChart.x, lineChart.y)
        lineChart.set_labels('Variable independiente', 'Variable dependiente')
        return lineChart.print_to_imgb64()

    def print_sigmoidal_chart_demo(self):
        lineChart = LineChart()
        lineChart.x = np.arange(-5.0, 5.0, 0.1)
        ##Se puede ajustar la pendiente y la intersecci√≥n para verificar los cambios en el gr√°fico
        lineChart.y = 1-4/( 1 + np.power(3, lineChart.x-2) )
        #plt.figure(figsize=(8,6))
        lineChart.plt.plot(lineChart.x, lineChart.y)
        lineChart.set_labels('Variable independiente', 'Variable dependiente')
        return lineChart.print_to_imgb64()

    '''
    Ejemplo de Regresi√≥n No-Lineal.
    Por ejemplo, intentaremos fijar un modelo no lineal a los puntos correspondientes al GDP de China entre
    los a√±os 1960 y 2014. Descargaremos un set de datos con dos columnas, la primera, un a√±o entre 1960 y 2014,
    la segunda, el ingreso anual de China en d√≥lares estadounidenses para ese a√±o.
    '''
    def read_source_data(self):
        self._df = pd.read_csv( self.__path_source_data + "china_gdp.csv")

    '''
    Marcando el set de datos.
    Asi es como los puntos de datos se ven. Se parece a una funci√≥n l√≥gica o exponencial. El crecimiento
    es leve, luego a partir de 2005 en adelante, el crecimiento ya es m√°s notorio. Y finalmente, desacelera
    suavemente a principio del a√±o 2010.
    '''
    def no_lineal_demo(self):
        self.read_source_data()

        lineChart = LineChart()
        lineChart.xdata, lineChart.ydata = (self._df["Year"].values, self._df["Value"].values)
        lineChart.plt.figure(figsize = (8,5))
        lineChart.plt.plot(lineChart.xdata, lineChart.ydata, 'ro')
        lineChart.set_labels('Year', 'GDP')
        return lineChart.print_to_imgb64()

    '''
    Eligiendo un modelo
    A primera vista, determinamos que la funci√≥n l√≥gica podr√≠a ser una buena primera aproximaci√≥n,
    ya que tiene la propiedad de comenzar con un crecimiento leve, aumentando en el medio y luego descendiendo
    nuevamente hacia el final; como se ve debajo:
    '''
    def no_lineal_demo2(self):
        self.read_source_data()

        lineChart = LineChart()
        lineChart.x = np.arange(-5.0, 5.0, 0.1)
        lineChart.y = 1.0 / (1.0 + np.exp(-lineChart.x))
        lineChart.plt.plot(lineChart.x, lineChart.y)
        lineChart.set_labels('Variable independiente', 'Variable dependiente')

        return lineChart.print_to_imgb64()

    '''
    La f√≥rumla para la funci√≥n log√≠stica es la siguiente: ùëåÃÇ =11+ùëíùõΩ1(ùëã‚àíùõΩ2)
    ùõΩ1: Controla lo llano de la curva,
    ùõΩ2: Lleva la curva sobre el eje x.

    Construyendo el Modelo
    Ahora, construyamos nuestro modelo de regresi√≥n e inicialicemos sus par√°metros.
    '''
    def sigmoid(self, x, beta_1, beta_2):
        y = 1 / (1 + np.exp(-beta_1*(x-beta_2)))
        return y

    def print_sigmoid_chart(self, beta_1, beta_2):
        self.read_source_data()

        lineChart = LineChart()
        lineChart.xdata, lineChart.ydata = (self._df["Year"].values, self._df["Value"].values)

        #funci√≥n log√≠stica
        Y_pred = self.sigmoid(lineChart.xdata, beta_1 , beta_2)

        #predicci√≥n de puntos
        lineChart.plt.plot(lineChart.xdata, Y_pred*15000000000000.)
        lineChart.plt.plot(lineChart.xdata, lineChart.ydata, 'ro')

        return lineChart.print_to_imgb64()

    '''
    Nuestra tarea aqu√≠ es encontrar los mejores par√°metros para nuestro modelo.
    Normalicemos primero nuestro x e y:
    '''
    def normalize_data(self, lineChart):
        xdata = lineChart.xdata / max(lineChart.xdata)
        ydata = lineChart.ydata / max(lineChart.ydata)

        lineChart.xdata = xdata
        lineChart.ydata = ydata

    '''
    ¬øC√≥mo podemos encontrar los mejores par√°metros para nuestra linea?
    podemos utilizar curve_fit la cual utiliza cuadrados m√≠nimos no lineales para cuadrar con la funci√≥n sigmoide.
    Los valores √≥ptimos para los par√°metros que suman los residuos cuadrados de sigmoid(xdata, *popt) -
    ydata minimizado.

    popt son nuestros par√°metros optimizados.
    '''
    def get_normalized_data(self, lineChart):
        self.normalize_data(lineChart)
        self._popt, self._pcov = curve_fit(self.sigmoid, lineChart.xdata, lineChart.ydata)
        print(self._popt)
        #imprimir los par√°metros finales
        print(" beta_1 = %f, beta_2 = %f" % (self._popt[0], self._popt[1]))

    '''Ahora dibujamos nuestro modelo de regresi√≥n.'''
    def print_regresion_model_chart(self, beta_1, beta_2):
        self.read_source_data()
        lineChart = LineChart()
        lineChart.xdata, lineChart.ydata = (self._df["Year"].values, self._df["Value"].values)
        print('****************')
        print(lineChart.xdata, lineChart.ydata)
        print('****************')

        # Normalizaci√≥n
        self.get_normalized_data(lineChart)
        print('****************')
        print(lineChart.xdata, lineChart.ydata)
        print('****************')

        x = np.linspace(1960, 2015, 55)
        lineChart.x = x / max(x)
        lineChart.plt.figure(figsize=(8,5))
        lineChart.y = self.sigmoid(lineChart.x, *self._popt)
        lineChart.plt.plot(lineChart.xdata, lineChart.ydata, 'ro', label='data')
        lineChart.plt.plot(lineChart.x, lineChart.y, linewidth=3.0, label='fit')
        lineChart.plt.legend(loc='best')
        lineChart.set_labels('Year', 'GDP')

        self.calculate_model_accuracy(lineChart)

        return lineChart.print_to_imgb64()


    '''
    Pr√°ctica
    ¬øPuedes calcular cual es la exactitud de nuestro modelo?
    '''
    def calculate_model_accuracy(self, lineChart):
        # divide los datos en entrenamiento y prueba
        msk = np.random.rand(len(self._df)) < 0.8
        train_x = lineChart.xdata[msk]
        test_x = lineChart.xdata[~msk]
        train_y = lineChart.ydata[msk]
        test_y = lineChart.ydata[~msk]

        # construye el modelo utilizando el set de entrenamiento
        popt, pcov = curve_fit(self.sigmoid, train_x, train_y)

        # predecir utilizando el set de prueba
        y_hat = self.sigmoid(test_x, *popt)

        # evaluation
        print("Promedio de error absoluto: %.2f" % np.mean(np.absolute(y_hat - test_y)))
        print("Suma residual de cuadrados (MSE): %.2f" % np.mean((y_hat - test_y) ** 2))
        print("R2-score: %.2f" % r2_score(y_hat , test_y) )

noLineal = NoLineal()
